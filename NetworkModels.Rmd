---
title: "Statistical modeling of visual cortical neurons"
output: pdf_document
author: "Cristian Bargiacchi, Christian Mancini"
date: "`r format(Sys.time(), '%d %B %Y')`" 
subject: "Network Analysis"
---

```{r, include=FALSE, eval=FALSE}
library(rmarkdown)
render("NetworkModels.Rmd", output_format = "pdf_document")
```

```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)
```

```{r brasa-tutto, include=FALSE}
rm(list = ls())
```

# Preliminary steps

```{r import-library, message=FALSE}
library(igraph)
library(ergm)
library(intergraph)
library(sbm)
library(ggplot2)
```

We first need to load our data using `igraph`. Data can be found [here](https://github.com/cMancio00/sand-2024/neurons/main/Data)

```{r import-data}
neurons_g <- read_graph("Data/mouse_visual.cortex_2.graphml","graphml")
Y = as_adjacency_matrix(neurons_g, sparse = F)
diag(Y) = NA
```

For starting the modeling we first have to convert an igraph object to a network one.

The conversion retains the order of the nodes but we also have to pass the attributes.

```{r data-convertion, message=FALSE, warning=FALSE}
neurons = network(Y, directed = T)
neurons %v% "type1" = vertex_attr(neurons_g,"type1",V(neurons_g))
neurons %v% "type2" = vertex_attr(neurons_g, "type2",V(neurons_g))
```

Now we are good to go!

# Homogeneous Simple Random Graph

Let's start with the simplest model.

**Assumptions**:

-   The probability of forming a tie is the **same** for every pair.

```{r message=FALSE, results=FALSE}
srg_homo = ergm(neurons ~ edges) 
```

```{r}
summary(srg_homo)
```

This model corresponds to a logistic regression, so we can interpret the result as odds:

```{r include=FALSE}
odds = exp(srg_homo$coefficients)
```

> The odds of observing a relation between two randomly selected nodes is about `r sprintf("%.2f", (1-odds)*100)`% lower than that of not observing it.

# Non-Homogeneous Simple Random Graph

**Assumptions**:

-   The same probability of forming a tie is relaxed.
-   Takes in consideration sender and receiver effect

> Since some node do not have in or out degree, those parameter will be set to `-inf`, so the model can't be used, but it can be estimated.

```{r message=FALSE, results=FALSE, eval=FALSE}
srg_no_homo = ergm(neurons ~ edges + sender + receiver,
                   control = control)
```

# Dyad independence model

**Assumptions**:

-   Dyads are independents and follows a *Multinomial* distribution
-   We take in consideration the reciprocity parameter $\gamma_{ij}$ (*mutual*)

## Classic p1 model

**Assumptions**:

-   the reciprocity parameter is $\gamma =\gamma_{ij}$
-   $\mu_{ij}$ depends additively from on the sender and receiver effect of node $i$ and $j$ involved.

```{r message=FALSE, warning=FALSE, results=FALSE, eval=FALSE}
p1_classic = ergm(neurons ~ edges + sender + receiver + mutual,
                  control = control.ergm(seed = 1))
```

## Sender and reciver independency assumption

We now construct 3 p1 model to check for *reciprocity* with the following assumptions:

1.  Sender effect independent
2.  Receiver effect independent
3.  Sender and receiver effect independent (equals to non-homogeneous SRG)

> For the same reasons explained in the non-homogeneous SRG, these models can't be estimated. The coefficients are set to `-inf`.

```{r message=FALSE, results=FALSE, eval=FALSE}
p1_sender_ind = ergm(neurons ~ edges + receiver + mutual,
                     control = control.ergm(seed = 1))
```

```{r message=FALSE, results=FALSE, eval=FALSE}
p1_receiver_ind = ergm(neurons ~ edges + sender + mutual,
                       control = control.ergm(seed = 1))
```

```{r message=FALSE, results=FALSE, eval=FALSE}
p1_mutual_only = ergm(neurons ~ edges + mutual,
                      control = control.ergm(seed = 1))
```

At this point we can just relay on the SRG. The next step is to include nodal attributes and exploit the background knowledge that we have of this network. We want to exploit the starts that are cleary visible in the network. Let's do one step at a time.

# Nodal attributes

In this part of the analysis we include nodal attributes to explore *homophily* and *main* effects.

-   **Main effect**: Nodes of a specific type have more chance to form ties

-   **Homophily effect** Nodes of a specific type have more chance to form ties between nodes of the same type

> As saw in the descriptive analysis we expect to observe dissortative mixing.

Since we only have categorical attributes we will use:

-   `nodefactor()` to include main effect
-   `nodematch()` to include homophily effect

Let's explore "*type1*" nodal attribute.

```{r message=FALSE, results=FALSE}
main_homo_type_one = ergm(neurons ~ edges + nodefactor("type1") + nodematch("type1"), 
            control = control.ergm(seed = 1)) 

```

```{r}
summary(main_homo_type_one)
```

As we expect, the *Dissortative mixing* is captured. The probability of forming ties with nodes of the same type is `r sprintf("%.2f", (1-(exp(-4.10482)))*100)`% lower, with respect to probability of forming ties with different one. Moreover, "*Characterized pyramidal neuron*" have more chances to form ties (which is true because they start the synapses). More precisely, the odds is `r sprintf("%.2f", exp(4.12940))` times higher respect to a "*Cell body in EM volume*".

Now we use *"type2"* attribute, but only as main effect, and we remove `mutual` since it is estimated as `-inf`.

> We exclude homophily, since all the coefficents will result non significants.

```{r message=FALSE, results=FALSE}
main_type_two = ergm(neurons ~ edges + nodefactor("type2"),
            control = control.ergm(seed = 1)) 
```

```{r}
summary(main_type_two)
```

We basically got the same conclusions. Since the reference is "*NA*" which can only be "*Characterized pyramidal neuron*", the odds of form a tie are smaller if a node is "*excitatory*" or "*inhibitory*".

Let's now put all together:

```{r message=FALSE, results=FALSE}
main_homo = ergm(neurons ~ edges + nodefactor("type1") + nodefactor("type2") 
                 + nodematch("type1"), 
            control = control.ergm(seed = 1)) 
```
```{r}
summary(main_homo)
```
We can see that the main effect of being a *Dendritic fragment* is not significant, so the tendency to form more ties than by chance depends only of being a *Characterized pyramidal neuron* or not. This is a good thing, since it reflect our descriptive analysis. 

We can now compare BIC for these models including nodal attributes.

```{r include=FALSE}
bic_main_homo_type_one <- sprintf("%.2f", BIC(main_homo_type_one))
bic_main_type_two <- sprintf("%.2f", BIC(main_type_two))
bic_main_homo <- sprintf("%.2f", BIC(main_homo))
```

| Model              | BIC                        |
|--------------------|----------------------------|
| main_Homo_Type_One | `r bic_main_homo_type_one` |
| main_Type_Two      | `r bic_main_type_two`      |
| main_Homo          | `r bic_main_homo`          |

According to `BIC` the full model is better.

# Nodal attributes (Binary)

Let's repeat the above analysis but using new attributes which are the binarization of the real ones.

As reference category we choose "*Characterized pyramidal neuron*" (for *type1*) and "*Postsynaptic excitatory target*" (for *type2*).

Generate the new attributes:

```{r message=FALSE, results=FALSE}
type1.new = rep(0, 195)
type1.new[vertex_attr(neurons_g,"type1") == "Characterized pyramidal neuron"] = 1
type1.new
neurons %v% "type1.new" = type1.new

type2.new = rep(0, 195)
type2.new[vertex_attr(neurons_g,"type2") == "Postsynaptic excitatory target"] = 1
type2.new
neurons %v% "type2.new" = type2.new
```

Estimate all the models again:

```{r message=FALSE, results=FALSE}
main_homo_type_one_binary = ergm(neurons ~ edges + nodefactor("type1.new") 
                                 + nodematch("type1.new"), 
            control = control.ergm(seed = 1))

main_type_two_binary = ergm(neurons ~ edges + nodefactor("type2.new"),
            control = control.ergm(seed = 1))

main_homo_binary = ergm(neurons ~ edges + nodefactor("type1.new") 
                        + nodefactor("type2.new") + nodematch("type1.new"), 
            control = control.ergm(seed = 1)) 
```

```{r include=FALSE}
bic_main_homo_type_one_binary <- sprintf("%.2f", BIC(main_homo_type_one_binary))
bic_main_type_two_binary <- sprintf("%.2f", BIC(main_type_two_binary))
bic_main_homo_binary <- sprintf("%.2f", BIC(main_homo_binary))
```

| Model                     | BIC                               |
|---------------------------|-----------------------------------|
| main_homo_type_one_binary | `r bic_main_homo_type_one_binary` |
| main_type_two_binary      | `r bic_main_type_two_binary`      |
| main_homo_binary          | `r bic_main_homo_binary`          |

According to `BIC` the new model with just "*type1.new*" is the best for now with a score of `r sprintf("%.2f", BIC(main_homo_type_one_binary))`.

Let's explore the summary of the model

```{r}
summary(main_homo_type_one_binary)
```

As we can see every parameter is significant. The interpretation is the same as before.

# Markov Model

We move in the direction of including stars. Given the best model until now, we add parameters.

We add the `instar(2)` and `triangles` parameter. Unfortunately, `ostar(2)` can't be used due to model degeneracy.

```{r message=FALSE, warning=FALSE}
markov = ergm(neurons ~ edges + nodefactor("type1.new") + 
              nodematch("type1.new") + istar(2) + triangles, 
             control = control.ergm(seed = 1))  
```
```{r}
summary(markov)
```
Let's tweak this model a bit. We know that no triangles are present in the network, so we remove it and see if `BIC` improves. We also take in consideration `nodefactor("type2.new")`.

```{r message=FALSE, warning=FALSE}
markov_no_triangles = ergm(neurons ~ edges + nodefactor("type1.new") 
                           + nodematch("type1.new") + nodefactor("type2.new") + istar(2), 
             control = control.ergm(seed = 1))
```

```{r}
summary(markov_no_triangles)
```

The result of basic Markov models are summarized in the table below.

```{r include=FALSE}
bic_markov <- sprintf("%.2f", BIC(markov))
bic_markov_no_triangles <- sprintf("%.2f", BIC(markov_no_triangles))

```

| Model                     | BIC                               |
|---------------------------|-----------------------------------|
| markov                    | `r bic_markov`                    |
| markov_no_triangles       | `r bic_markov_no_triangles`       |

# Markov with alternating k_stars

Since we want to exploit the stars in the graph, a solution is using the "*alternating k_stars*".
We are not interest in "*alternating k-paths*" since they are not observed in the network.

> Maybe what follows is a little cheating or inaccurate, but the only way to let the estimation end is using a *Stochastic-Approximation*.

```{r message=FALSE, warning=FALSE}
k_star = ergm(neurons ~ edges + nodefactor("type1.new") + nodefactor("type2.new") 
              + nodematch("type1.new") + gwidegree(decay = 1, fixed = TRUE) 
              + gwodegree(decay = 1, fixed = TRUE) ,
             control = control.ergm(seed = 1, main.method = "Stochastic-Approximation"))
```
```{r}
summary(k_star)
```
This is the best model we can get.

# Social Circuits

We also propose a social circuit model, but it has worst fit with respect to the previus models.
we quote it anyway for completeness.

```{r message=FALSE, warning=FALSE}
social = ergm(neurons ~ edges + nodefactor("type1.new") + nodefactor("type2.new") 
             + nodematch("type1.new") + gwdsp(decay = 1, fixed = T),
             control = control.ergm(seed=1, main.method = "Stochastic-Approximation" ))
```
```{r}
summary(social)
```

# Recap of models

To recap the performances of models the best ones are `markov_no_triangles` and `k_star` (which is however estimated with a stochastic approach).

The table below recap the goodness of fit of the best models compared to the homogeneous SRG.

```{r include=FALSE}
bic_srg_homo <- sprintf("%.2f", BIC(srg_homo))
bic_k_star <- sprintf("%.2f", BIC(k_star))
```

| Model                     | BIC                               |
|---------------------------|-----------------------------------|
| srg_homo                  | `r bic_srg_homo`                  |
| markov_no_triangles       | `r bic_markov_no_triangles`       |
| k_star                    | `r bic_k_star`                    |

# Simulazione

Now that we have chosen the two best models, we can test them in a simulation to see if they can model the network. The reference will be the performance of the homogeneous simple random graph. 

```{r message=FALSE, warning=FALSE}
nsim=100
sim_srg = simulate(srg_homo, nsim = nsim, verbose = TRUE, seed = 1)
sim_markov_no_triangles = simulate(k_star, nsim = nsim, verbose = TRUE, seed = 1)
sim_k_star = simulate(k_star, nsim = nsim, verbose = TRUE, seed = 1)
```
```{r message=FALSE, warning=FALSE}
fnc = function(xx){
  ig = asIgraph(xx)
  tr = transitivity(ig)
  ideg = sd(degree(ig, mode = "in"))
  odeg = sd(degree(ig, mode = "out"))
  return(c(tr, ideg, odeg))
}

null.distr.srg = matrix(,nsim,3)
null.distr.markov_no_triangles = matrix(,nsim,3)
null.distr.k_star = matrix(,nsim,3)
for(b in 1:nsim){
  null.distr.srg[b,]  = fnc(sim_srg[[b]])
  null.distr.markov_no_triangles[b,]  = fnc(sim_markov_no_triangles[[b]])
  null.distr.k_star[b,]  = fnc(sim_k_star[[b]])
}
```

## SRG simulation
```{r}
dev.new()
par(mfrow = c(3,1))
hist(unlist(null.distr.srg[,1]), xlab = "transitivity");
abline(v = transitivity(neurons_g), col = "red")
hist(unlist(null.distr.srg[,2]), xlim = c(0.25,1.25),xlab = "in-degree");
abline(v = sd(degree(neurons_g, mode = "in")), col = "red")
hist(unlist(null.distr.srg[,3]), xlim = c(1,5.25),xlab = "out-degree");
abline(v = sd(degree(neurons_g, mode = "out")), col = "red")

```
## Markov without triangles simulation
```{r}
dev.new()
par(mfrow = c(3,1))
hist(unlist(null.distr.markov_no_triangles[,1]), xlab = "transitivity");
abline(v = transitivity(neurons_g), col = "red")
hist(unlist(null.distr.markov_no_triangles[,2]), xlab = "in-degree");
abline(v = sd(degree(neurons_g, mode = "in")), col = "red")
hist(unlist(null.distr.markov_no_triangles[,3]),
     xlim = c(4,5.25),xlab = "out-degree");
abline(v = sd(degree(neurons_g, mode = "out")), col = "red")
```

## Alternating k-stars simulation
```{r fig.show="hold", out.width="50%", fig.cap="prova cap"}
dev.new()
par(mfrow = c(3,1))
hist(unlist(null.distr.k_star[,1]), xlab = "transitivity");
abline(v = transitivity(neurons_g), col = "red")
hist(unlist(null.distr.k_star[,2]), xlab = "in-degree");
abline(v = sd(degree(neurons_g, mode = "in")), col = "red")
hist(unlist(null.distr.k_star[,3]), xlim = c(4,5.25),xlab = "out-degree");
abline(v = sd(degree(neurons_g, mode = "out")), col = "red")
```

# Conclusions from model simulations

We can see a marked improvement over the SRG. We are able to model transitivity and in degree. Unfortunately, we still cannot model the outgoing degree (the stars) with the estimated models. We can however be satisfied with the closeness of the estimate. As far as the choice of model is concerned, having similar performance, we prefer the Markov model without triangles because it was estimated using the MCMC procedure.

# SBM
## Preliminary steps

We start by making an undirected version of our graph to work with. 

```{r message=FALSE, warning=FALSE}
neurons_g_undirected <- as.undirected(neurons_g, mode="collapse" )
Y_undirected = as_adjacency_matrix(neurons_g_undirected, sparse = F)
```

```{r eval=FALSE, include=FALSE}
plotMyMatrix(Y_undirected, dimLabels = list(row = 'neurons', col = 'neurons'))
```
![adjacency]("Plots/SBM/adjacency.jpg")

## Bernoulli
```{r}
sbm1 = estimateSimpleSBM(Y_undirected, "bernoulli", dimLabels = 'neurons', 
                         estimOptions = list(verbosity = 1))
```
```{r}
sbm1
sbm1$nbBlocks; sbm1$blockProp; round(sbm1$connectParam$mean,3)
plot(sbm1, type = "data") ## stessa matrice di adiacenza vista prima, però shifta righe e colonne per mettere vicini nodi dello stesso gruppo
# nodes are ordered wrt to the block they belong to and blocks are highlighted
plot(sbm1, type = "expected")
# fitted connection probabilities
plot(sbm1, type = "meso")
# fitted connection probabilities 

# info on all estimated model is given in 
sbm1$storedModels

sbm1$memberships

plot(neurons_g_undirected, vertex.color = sbm1$memberships)
```

## Poisson
```{r}
sbm2 = estimateSimpleSBM(Y_undirected, "poisson", dimLabels = 'neurons', 
                         estimOptions = list(verbosity = 1))

sbm2



# selected number of blocks
sbm2$nbBlocks
# prior block probabilities
sbm2$blockProp
# connectivity parameters
round(sbm2$connectParam$mean,3)
#diag principale prob di osservare link intragruppo, outofdiag sono le prob di oss link tra membri di quei gruppi


# Let us graphically represent the data matrix 
# reordering rows and cols according to the estimated block in the SBM

plot(sbm2, type = "data", dimLabels = list(row = 'neurons', col= 'neurons'))

# or the average number of connections between neuronss
plot(sbm2, type = "expected", dimLabels = list(row = 'neurons', col= 'neurons'))

# or 
plot(sbm2, type = "meso", dimLabels = list(row = 'neurons', col= 'neurons'))

```
